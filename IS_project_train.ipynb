{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1gzEQut_E1HwMXLJk5CKuNoAcUDe4gBHe","timestamp":1701346428540}],"authorship_tag":"ABX9TyMX7oqGR2CSXoORaqmvgxw7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"JNZ7O8_J-Cy6"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np"]},{"cell_type":"code","source":["#################################################\n","# You can change this cell to update data list\n","train_lst = ['data_track1_1.csv', 'data_track1_2.csv', 'data_track2_1.csv', 'data_track2_2.csv']\n","val_lst = ['data_track1_val.csv', 'data_track2_val.csv']"],"metadata":{"id":"FfDh6eYx_pXJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#################################################\n","# DO NOT CHANGE THIS CELL(unless you have a better idea to preprocess the data)\n","train_data = np.loadtxt(train_lst[0], delimiter = \",\")\n","print(train_lst[0], \":\", train_data.shape)\n","for i in range(1, len(train_lst)):\n","    new_data = np.loadtxt(train_lst[i], delimiter = \",\")\n","    print(train_lst[i], \":\", new_data.shape)\n","    train_data = np.concatenate((train_data, new_data), axis=0)\n","num_train = train_data.shape[0]\n","\n","val_data = np.loadtxt(val_lst[0], delimiter = \",\")\n","print(val_lst[0], \":\", val_data.shape)\n","for i in range(1, len(val_lst)):\n","    new_data = np.loadtxt(val_lst[i], delimiter = \",\")\n","    print(val_lst[i], \":\", new_data.shape)\n","    val_data = np.concatenate((val_data, new_data), axis=0)\n","num_val = val_data.shape[0]\n","\n","data = np.concatenate((train_data, val_data), axis=0)\n","data = torch.from_numpy(data).float()\n","\n","processed_data = torch.nan_to_num(data, posinf=11.0)\n","means = torch.mean(processed_data, 0)\n","stds = torch.std(processed_data, 0)\n","norm_data = (processed_data - means) / stds"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S_QYrDuXfAZt","executionInfo":{"status":"ok","timestamp":1701444516321,"user_tz":-540,"elapsed":5238,"user":{"displayName":"­홍찬우 / 학생 / 전기·정보공학부","userId":"08630047600871876613"}},"outputId":"ed7e65ce-5529-45ad-dc55-6e85802377e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["data_track1_1.csv : (3340, 1083)\n","data_track1_2.csv : (3340, 1083)\n","data_track2_1.csv : (822, 1083)\n","data_track2_2.csv : (826, 1083)\n","data_track1_val.csv : (334, 1083)\n","data_track2_val.csv : (83, 1083)\n"]}]},{"cell_type":"code","source":["#################################################\n","# You can change this cell to update data list\n","input_dim = 1081\n","hidden_dim1 = 1000\n","hidden_dim2 = 500\n","\n","X_train = norm_data[:num_train, :-2]\n","X_val = norm_data[num_train:, :-2]\n","y_train = norm_data[:num_train, -1]\n","y_val = norm_data[num_train:, -1]\n","print(\"X_train:\", X_train.shape)\n","print(\"X_val:\", X_val.shape)\n","print(\"y_train:\", y_train.shape)\n","print(\"y_val:\", y_val.shape)"],"metadata":{"id":"EX3a9n0T_4u2","executionInfo":{"status":"ok","timestamp":1701444516322,"user_tz":-540,"elapsed":20,"user":{"displayName":"­홍찬우 / 학생 / 전기·정보공학부","userId":"08630047600871876613"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4d51ced5-f03c-4813-fc9c-f612cb986a39"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train: torch.Size([8328, 1081])\n","X_val: torch.Size([417, 1081])\n","y_train: torch.Size([8328])\n","y_val: torch.Size([417])\n"]}]},{"cell_type":"code","source":["#################################################\n","# You can change this cell to make variations to model\n","class Model(nn.Module):\n","    def __init__(self, input_dim, hidden_dim1, hidden_dim2):\n","        super(Model, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n","        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n","        self.fc3 = nn.Linear(hidden_dim2, 1)\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = F.tanh(x)\n","        x = self.fc2(x)\n","        x = F.relu(x)\n","        x = self.fc3(x)\n","        return x"],"metadata":{"id":"jTZEEy-W-uoK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Model(input_dim, hidden_dim1, hidden_dim2)\n","criterion = nn.MSELoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.0005)\n","\n","for epoch in range(50):\n","    loss_train = 0\n","    for i in range(X_train.shape[0]):\n","        X = X_train[i, :]\n","        y = y_train[i]\n","        s = model(X)\n","        loss = criterion(s, y)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        loss_train = loss_train + loss\n","\n","    loss_val = 0\n","    for j in range(X_val.shape[0]):\n","        X = X_val[j, :]\n","        y = y_val[j]\n","        s = model(X)\n","        loss_val = loss_val + criterion(s, y)\n","    print(epoch, \":\", loss_train / X_train.shape[0], loss_val / X_val.shape[0])"],"metadata":{"id":"0vBDfm_x_9FD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0a4b900f-6942-496d-d826-344587582fc7","executionInfo":{"status":"ok","timestamp":1701445824373,"user_tz":-540,"elapsed":1307556,"user":{"displayName":"­홍찬우 / 학생 / 전기·정보공학부","userId":"08630047600871876613"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["0 : tensor(0.3214, grad_fn=<DivBackward0>) tensor(0.5859, grad_fn=<DivBackward0>)\n","1 : tensor(0.2246, grad_fn=<DivBackward0>) tensor(0.3798, grad_fn=<DivBackward0>)\n","2 : tensor(0.1886, grad_fn=<DivBackward0>) tensor(0.3202, grad_fn=<DivBackward0>)\n","3 : tensor(0.1703, grad_fn=<DivBackward0>) tensor(0.2963, grad_fn=<DivBackward0>)\n","4 : tensor(0.1588, grad_fn=<DivBackward0>) tensor(0.2804, grad_fn=<DivBackward0>)\n","5 : tensor(0.1500, grad_fn=<DivBackward0>) tensor(0.2620, grad_fn=<DivBackward0>)\n","6 : tensor(0.1428, grad_fn=<DivBackward0>) tensor(0.2460, grad_fn=<DivBackward0>)\n","7 : tensor(0.1370, grad_fn=<DivBackward0>) tensor(0.2320, grad_fn=<DivBackward0>)\n","8 : tensor(0.1320, grad_fn=<DivBackward0>) tensor(0.2206, grad_fn=<DivBackward0>)\n","9 : tensor(0.1276, grad_fn=<DivBackward0>) tensor(0.2095, grad_fn=<DivBackward0>)\n","10 : tensor(0.1238, grad_fn=<DivBackward0>) tensor(0.2042, grad_fn=<DivBackward0>)\n","11 : tensor(0.1203, grad_fn=<DivBackward0>) tensor(0.1995, grad_fn=<DivBackward0>)\n","12 : tensor(0.1172, grad_fn=<DivBackward0>) tensor(0.1952, grad_fn=<DivBackward0>)\n","13 : tensor(0.1143, grad_fn=<DivBackward0>) tensor(0.1899, grad_fn=<DivBackward0>)\n","14 : tensor(0.1117, grad_fn=<DivBackward0>) tensor(0.1865, grad_fn=<DivBackward0>)\n","15 : tensor(0.1093, grad_fn=<DivBackward0>) tensor(0.1827, grad_fn=<DivBackward0>)\n","16 : tensor(0.1072, grad_fn=<DivBackward0>) tensor(0.1798, grad_fn=<DivBackward0>)\n","17 : tensor(0.1051, grad_fn=<DivBackward0>) tensor(0.1756, grad_fn=<DivBackward0>)\n","18 : tensor(0.1033, grad_fn=<DivBackward0>) tensor(0.1726, grad_fn=<DivBackward0>)\n","19 : tensor(0.1016, grad_fn=<DivBackward0>) tensor(0.1711, grad_fn=<DivBackward0>)\n","20 : tensor(0.1000, grad_fn=<DivBackward0>) tensor(0.1691, grad_fn=<DivBackward0>)\n","21 : tensor(0.0985, grad_fn=<DivBackward0>) tensor(0.1648, grad_fn=<DivBackward0>)\n","22 : tensor(0.0971, grad_fn=<DivBackward0>) tensor(0.1630, grad_fn=<DivBackward0>)\n","23 : tensor(0.0957, grad_fn=<DivBackward0>) tensor(0.1583, grad_fn=<DivBackward0>)\n","24 : tensor(0.0945, grad_fn=<DivBackward0>) tensor(0.1567, grad_fn=<DivBackward0>)\n","25 : tensor(0.0933, grad_fn=<DivBackward0>) tensor(0.1536, grad_fn=<DivBackward0>)\n","26 : tensor(0.0922, grad_fn=<DivBackward0>) tensor(0.1521, grad_fn=<DivBackward0>)\n","27 : tensor(0.0911, grad_fn=<DivBackward0>) tensor(0.1494, grad_fn=<DivBackward0>)\n","28 : tensor(0.0902, grad_fn=<DivBackward0>) tensor(0.1477, grad_fn=<DivBackward0>)\n","29 : tensor(0.0892, grad_fn=<DivBackward0>) tensor(0.1446, grad_fn=<DivBackward0>)\n","30 : tensor(0.0883, grad_fn=<DivBackward0>) tensor(0.1414, grad_fn=<DivBackward0>)\n","31 : tensor(0.0875, grad_fn=<DivBackward0>) tensor(0.1408, grad_fn=<DivBackward0>)\n","32 : tensor(0.0868, grad_fn=<DivBackward0>) tensor(0.1373, grad_fn=<DivBackward0>)\n","33 : tensor(0.0860, grad_fn=<DivBackward0>) tensor(0.1370, grad_fn=<DivBackward0>)\n","34 : tensor(0.0853, grad_fn=<DivBackward0>) tensor(0.1350, grad_fn=<DivBackward0>)\n","35 : tensor(0.0846, grad_fn=<DivBackward0>) tensor(0.1326, grad_fn=<DivBackward0>)\n","36 : tensor(0.0839, grad_fn=<DivBackward0>) tensor(0.1310, grad_fn=<DivBackward0>)\n","37 : tensor(0.0833, grad_fn=<DivBackward0>) tensor(0.1297, grad_fn=<DivBackward0>)\n","38 : tensor(0.0826, grad_fn=<DivBackward0>) tensor(0.1274, grad_fn=<DivBackward0>)\n","39 : tensor(0.0820, grad_fn=<DivBackward0>) tensor(0.1280, grad_fn=<DivBackward0>)\n","40 : tensor(0.0815, grad_fn=<DivBackward0>) tensor(0.1272, grad_fn=<DivBackward0>)\n","41 : tensor(0.0809, grad_fn=<DivBackward0>) tensor(0.1238, grad_fn=<DivBackward0>)\n","42 : tensor(0.0804, grad_fn=<DivBackward0>) tensor(0.1235, grad_fn=<DivBackward0>)\n","43 : tensor(0.0799, grad_fn=<DivBackward0>) tensor(0.1225, grad_fn=<DivBackward0>)\n","44 : tensor(0.0794, grad_fn=<DivBackward0>) tensor(0.1210, grad_fn=<DivBackward0>)\n","45 : tensor(0.0788, grad_fn=<DivBackward0>) tensor(0.1193, grad_fn=<DivBackward0>)\n","46 : tensor(0.0784, grad_fn=<DivBackward0>) tensor(0.1200, grad_fn=<DivBackward0>)\n","47 : tensor(0.0780, grad_fn=<DivBackward0>) tensor(0.1174, grad_fn=<DivBackward0>)\n","48 : tensor(0.0775, grad_fn=<DivBackward0>) tensor(0.1171, grad_fn=<DivBackward0>)\n","49 : tensor(0.0771, grad_fn=<DivBackward0>) tensor(0.1159, grad_fn=<DivBackward0>)\n"]}]},{"cell_type":"code","source":["torch.save(model, \"/content/model.pt\")\n","torch.save(means, \"/content/means.pt\")\n","torch.save(stds, \"/content/stds.pt\")"],"metadata":{"id":"xzemm0pujw9j"},"execution_count":null,"outputs":[]}]}